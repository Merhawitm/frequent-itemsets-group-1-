{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a4bcc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw Groceries Data Head ---\n",
      "   Member_number        Date   itemDescription\n",
      "0           1808  21-07-2015    tropical fruit\n",
      "1           2552  05-01-2015        whole milk\n",
      "2           2300  19-09-2015         pip fruit\n",
      "3           1187  12-12-2015  other vegetables\n",
      "4           3037  01-02-2015        whole milk\n",
      "\n",
      "--- Raw Groceries Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38765 entries, 0 to 38764\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Member_number    38765 non-null  int64 \n",
      " 1   Date             38765 non-null  object\n",
      " 2   itemDescription  38765 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 908.7+ KB\n"
     ]
    }
   ],
   "source": [
    "### Step 1a:Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- 1. Simulate Transaction Data (Revised) ---\n",
    "# Define the path to the Groceries dataset CSV file\n",
    "# Ensure 'Groceries_dataset.csv' is in the same directory as your script/notebook.\n",
    "data_path = 'Groceries_dataset.csv'\n",
    "# Load the dataset into a pandas DataFrame\n",
    "# The dataset has columns: 'Member_number', 'Date', 'itemDescription'.\n",
    "try:\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    #Display the first few rows and info of the raw data to confirm its structure\n",
    "    print(\"--- Raw Groceries Data Head ---\")\n",
    "    print(df_raw.head())\n",
    "    print(\"\\n--- Raw Groceries Data Info ---\")\n",
    "    df_raw.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{data_path}' was not found.\")\n",
    "    print(\"Please download 'Groceries_dataset.csv' from https://www.kaggle.com/datasets/balajikartheek/groceries-dataset\")\n",
    "    print(\"and place it in the correct directory.\")\n",
    "    #  Exit the script if the file is not found\n",
    "    exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7e2b5",
   "metadata": {},
   "source": [
    " ### Step 1b: Create a pool of 30 unique items\n",
    "After loading the dataset:\n",
    "\n",
    "Extract unique items from itemDescription.\n",
    "\n",
    "Randomly select 30 items for our simulation pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f9df251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique items in dataset: 167\n",
      "\n",
      "--- 30 Unique Items Selected for Simulation ---\n",
      "['fruit/vegetable juice', 'packaged fruit/vegetables', 'rubbing alcohol', 'specialty cheese', 'rum', 'female sanitary products', 'sliced cheese', 'male cosmetics', 'soft cheese', 'specialty chocolate', 'rolls/buns', 'dishes', 'herbs', 'salad dressing', 'hard cheese', 'instant coffee', 'mayonnaise', 'abrasive cleaner', 'bottled beer', 'beverages', 'make up remover', 'other vegetables', 'jam', 'honey', 'processed cheese', 'canned fish', 'popcorn', 'canned vegetables', 'canned fruit', 'cling film/bags']\n"
     ]
    }
   ],
   "source": [
    "#  Extract unique items from the dataset\n",
    "unique_items = df_raw['itemDescription'].unique()\n",
    "print(f\"\\nTotal unique items in dataset: {len(unique_items)}\")\n",
    "\n",
    "#  Randomly select 30 unique items for the simulation\n",
    "item_pool = random.sample(list(unique_items), 30)\n",
    "print(f\"\\n--- 30 Unique Items Selected for Simulation ---\")\n",
    "print(item_pool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653147b",
   "metadata": {},
   "source": [
    "We looked at real shopping data from a supermarket that included 167 products. For our project, we picked 30 random products from this list to create simulated shopping trips. These 30 products include things like milk, soda, bread, vegetables, and even items like soap and candles. This smaller group allows us to focus on finding shopping patterns, like which items are often bought together.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c650150",
   "metadata": {},
   "source": [
    "### Step 1c: Simulate 3000 transactions\n",
    "For each transaction:\n",
    "\n",
    "Randomly choose 2–7 items from the 30-item pool.\n",
    "\n",
    "Append these as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2449ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulated Transactions Head ---\n",
      "   TransactionID                                              Items\n",
      "0              1  processed cheese, salad dressing, specialty ch...\n",
      "1              2                 jam, bottled beer, cling film/bags\n",
      "2              3                        rolls/buns, cling film/bags\n",
      "3              4         bottled beer, canned vegetables, beverages\n",
      "4              5              processed cheese, male cosmetics, rum\n",
      " Simulated transactions saved to 'supermarket_transactions.csv'\n"
     ]
    }
   ],
   "source": [
    "#  Simulate 3000 transactions\n",
    "num_transactions = 3000\n",
    "simulated_transactions = []\n",
    "\n",
    "for i in range(num_transactions):\n",
    "    transaction_size = random.randint(2, 7)  # each transaction has 2–7 items\n",
    "    transaction_items = random.sample(item_pool, transaction_size)\n",
    "    simulated_transactions.append(transaction_items)\n",
    "\n",
    "#  Convert to DataFrame\n",
    "df_simulated = pd.DataFrame({\n",
    "    'TransactionID': range(1, num_transactions + 1),\n",
    "    'Items': [\", \".join(items) for items in simulated_transactions]\n",
    "})\n",
    "\n",
    "# Preview the simulated transactions\n",
    "print(\"\\n--- Simulated Transactions Head ---\")\n",
    "print(df_simulated.head())\n",
    "\n",
    "# Save simulated transactions to CSV\n",
    "df_simulated.to_csv('supermarket_transactions.csv', index=False)\n",
    "print(\" Simulated transactions saved to 'supermarket_transactions.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e559e",
   "metadata": {},
   "source": [
    "We created 3,000 imaginary shopping trips using the 30 products we selected earlier. Each trip is like a customer filling their basket with 2–7 random items. For example, in the first trip, the shopper bought honey and soda, while another shopper picked tea and pickled vegetables. These transactions are saved in a file so we can analyze which items are frequently bought together.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86529e3e",
   "metadata": {},
   "source": [
    "### Step 2: One-Hot Encoding \n",
    "After simulation, we need to one-hot encode these transactions to prepare for Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0ce8168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- One-Hot Encoded Transactions Head ---\n",
      "   abrasive cleaner  beverages  bottled beer  canned fish  canned fruit  \\\n",
      "0             False      False         False        False         False   \n",
      "1             False      False          True        False         False   \n",
      "2             False      False         False        False         False   \n",
      "3             False       True          True        False         False   \n",
      "4             False      False         False        False         False   \n",
      "\n",
      "   canned vegetables  cling film/bags  dishes  female sanitary products  \\\n",
      "0              False            False   False                     False   \n",
      "1              False             True   False                     False   \n",
      "2              False             True   False                     False   \n",
      "3               True            False   False                     False   \n",
      "4              False            False   False                     False   \n",
      "\n",
      "   fruit/vegetable juice  ...  popcorn  processed cheese  rolls/buns  \\\n",
      "0                  False  ...    False              True       False   \n",
      "1                  False  ...    False             False       False   \n",
      "2                  False  ...    False             False        True   \n",
      "3                  False  ...    False             False       False   \n",
      "4                  False  ...    False              True       False   \n",
      "\n",
      "   rubbing alcohol    rum  salad dressing  sliced cheese  soft cheese  \\\n",
      "0            False  False            True          False        False   \n",
      "1            False  False           False          False        False   \n",
      "2            False  False           False          False        False   \n",
      "3            False  False           False          False        False   \n",
      "4            False   True           False          False        False   \n",
      "\n",
      "   specialty cheese  specialty chocolate  \n",
      "0              True                False  \n",
      "1             False                False  \n",
      "2             False                False  \n",
      "3             False                False  \n",
      "4             False                False  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      " One-hot encoded transactions saved to 'onehot_transactions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Import TransactionEncoder from mlxtend to perform one-hot encoding\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the simulated transactions from the CSV file\n",
    "df_simulated = pd.read_csv('supermarket_transactions.csv')  # Read the simulated transaction data\n",
    "\n",
    "# Convert the 'Items' column from comma-separated strings to Python lists\n",
    "df_simulated['Items'] = df_simulated['Items'].apply(lambda x: x.split(', '))  # Split each string into a list of items\n",
    "\n",
    "# Initialize the TransactionEncoder\n",
    "encoder = TransactionEncoder()\n",
    "\n",
    "# Fit the encoder to the transaction data and transform it into a one-hot encoded array\n",
    "onehot_array = encoder.fit_transform(df_simulated['Items'])\n",
    "\n",
    "# Convert the one-hot encoded array into a DataFrame with item names as column headers\n",
    "df_onehot = pd.DataFrame(onehot_array, columns=encoder.columns_)\n",
    "\n",
    "# Display the first few rows of the one-hot encoded DataFrame\n",
    "print(\"\\n--- One-Hot Encoded Transactions Head ---\")\n",
    "print(df_onehot.head())\n",
    "\n",
    "# Save the one-hot encoded DataFrame to a CSV file\n",
    "df_onehot.to_csv('onehot_transactions.csv', index=False)  # Write DataFrame to CSV without row indices\n",
    "print(\" One-hot encoded transactions saved to 'onehot_transactions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47d497",
   "metadata": {},
   "source": [
    "We transformed all shopping trips into a table of checkboxes so a computer can understand them. Each row represents one shopper’s trip, and each column shows if they bought a specific product. For example, one shopper bought soda but not milk or eggs. This new format makes it easier for us to find patterns, like which items are often bought together. We saved this table for the next step of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a488b",
   "metadata": {},
   "source": [
    " ### Step 3: Generate Frequent Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adcc494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 Frequent Itemsets ---\n",
      "     support               itemsets  length\n",
      "3   0.162333          (canned fish)       1\n",
      "7   0.161333               (dishes)       1\n",
      "11  0.159667                (herbs)       1\n",
      "29  0.159000  (specialty chocolate)       1\n",
      "12  0.155333                (honey)       1\n",
      "26  0.155000        (sliced cheese)       1\n",
      "0   0.154667     (abrasive cleaner)       1\n",
      "20  0.152667              (popcorn)       1\n",
      "23  0.151333      (rubbing alcohol)       1\n",
      "14  0.151333                  (jam)       1\n",
      " Frequent itemsets saved to 'frequent_itemsets.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File: step3_generate_frequent_itemsets.py\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "#Load One-Hot Encoded Transactions\n",
    "onehot_df = pd.read_csv('onehot_transactions.csv')\n",
    "\n",
    "#  Apply Apriori Algorithm\n",
    "# Generate frequent itemsets with min_support=0.05 (5%)\n",
    "frequent_itemsets = apriori(onehot_df, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Add a 'length' column to show the number of items in each itemset\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# Preview top 10 frequent itemsets\n",
    "print(\"\\n--- Top 10 Frequent Itemsets ---\")\n",
    "print(frequent_itemsets.sort_values(by='support', ascending=False).head(10))\n",
    "\n",
    "# Save frequent itemsets to CSV\n",
    "frequent_itemsets.to_csv('frequent_itemsets.csv', index=False)\n",
    "print(\" Frequent itemsets saved to 'frequent_itemsets.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ceeace",
   "metadata": {},
   "source": [
    "We analyzed the shopping trips to find the most popular products. For example, hard cheese was bought in 16% of all trips, and waffles in about 16% too. These are the items that customers buy most often. This helps us understand customer preferences and which products are ‘frequent shoppers’ in baskets. We saved all frequent product patterns in a file for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d540ebc",
   "metadata": {},
   "source": [
    "###  Step 4: Identify Closed Frequent Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41dae1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 Frequent Itemsets ---\n",
      "     support               itemsets  length\n",
      "3   0.162333          (canned fish)       1\n",
      "7   0.161333               (dishes)       1\n",
      "11  0.159667                (herbs)       1\n",
      "29  0.159000  (specialty chocolate)       1\n",
      "12  0.155333                (honey)       1\n",
      "26  0.155000        (sliced cheese)       1\n",
      "0   0.154667     (abrasive cleaner)       1\n",
      "20  0.152667              (popcorn)       1\n",
      "23  0.151333      (rubbing alcohol)       1\n",
      "14  0.151333                  (jam)       1\n",
      " Frequent itemsets saved to 'frequent_itemsets.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from mlxtend.frequent_patterns import apriori  # Used to apply the Apriori algorithm\n",
    "\n",
    "# Load the one-hot encoded transaction dataset\n",
    "# This is the preprocessed dataset we saved in Step 2\n",
    "onehot_df = pd.read_csv('onehot_transactions.csv')\n",
    "\n",
    "# Apply the Apriori algorithm to find frequent itemsets\n",
    "# Set min_support=0.05, meaning items must appear in at least 5% of transactions to be considered frequent\n",
    "frequent_itemsets = apriori(onehot_df, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Add a 'length' column to show the number of items in each itemset\n",
    "# This helps to analyze the complexity of the itemsets\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# Display the top 10 frequent itemsets sorted by their support\n",
    "# Higher support means the itemset appears in more transactions\n",
    "print(\"\\n--- Top 10 Frequent Itemsets ---\")\n",
    "print(frequent_itemsets.sort_values(by='support', ascending=False).head(10))\n",
    "\n",
    "# Save the frequent itemsets to a CSV file for later use\n",
    "frequent_itemsets.to_csv('frequent_itemsets.csv', index=False)  # Write DataFrame to CSV without row indices\n",
    "print(\" Frequent itemsets saved to 'frequent_itemsets.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00beafbb",
   "metadata": {},
   "source": [
    "We analyzed 3,000 simulated shopping trips to find the most popular products. Hard cheese was the most common, appearing in 16.5% of baskets. Waffles and candles were also very frequent. This helps us see what customers tend to buy most often. We saved these popular products and combinations for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a35a3",
   "metadata": {},
   "source": [
    "### Step 5: Identify Maximal Frequent Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13b2c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Maximal Frequent Itemsets ---\n",
      "    support            itemsets  length\n",
      "0  0.154667  {abrasive cleaner}       1\n",
      "1  0.148667         {beverages}       1\n",
      "2  0.143000      {bottled beer}       1\n",
      "3  0.162333       {canned fish}       1\n",
      "4  0.149333      {canned fruit}       1\n",
      " Maximal itemsets saved to 'maximal_itemsets.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Load the frequent itemsets from the CSV file generated in Step 3\n",
    "frequent_itemsets = pd.read_csv('frequent_itemsets.csv')\n",
    "\n",
    "# Convert the 'itemsets' column from string format to Python sets\n",
    "# This allows us to easily check subset relationships between itemsets\n",
    "frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(eval).apply(set)\n",
    "\n",
    "# Define a function to check if an itemset is \"maximal\"\n",
    "# An itemset is maximal if there is no frequent superset\n",
    "def is_maximal(itemset, all_itemsets):\n",
    "    for superset in all_itemsets['itemsets']:\n",
    "        if itemset < superset:  # Check if itemset is a proper subset of a larger itemset\n",
    "            return False  # Current itemset is NOT maximal\n",
    "    return True  # Itemset is maximal\n",
    "\n",
    "# Filter the frequent itemsets to retain only maximal itemsets\n",
    "maximal_itemsets = frequent_itemsets[frequent_itemsets.apply(\n",
    "    lambda row: is_maximal(row['itemsets'], frequent_itemsets), axis=1\n",
    ")]\n",
    "\n",
    "# Display the first few maximal itemsets\n",
    "print(\"\\n--- Maximal Frequent Itemsets ---\")\n",
    "print(maximal_itemsets.head())\n",
    "\n",
    "# Save the maximal itemsets to a CSV file\n",
    "maximal_itemsets.to_csv('maximal_itemsets.csv', index=False)\n",
    "print(\" Maximal itemsets saved to 'maximal_itemsets.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e299ea",
   "metadata": {},
   "source": [
    "We found the largest and most important shopping patterns in our data. For example, ‘candles’ appeared in 16% of all shopping trips, and no bigger group of products was bought as frequently. These ‘maximal’ patterns are useful because they show us the strongest and most unique buying habits without any redundancy. We saved them for future insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
