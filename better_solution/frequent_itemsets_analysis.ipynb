{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Frequent Itemsets Analysis: Closed vs Maximal\n",
       "\n",
       "## Group Assignment for Data Mining / Warehousing\n",
       "\n",
       "---\n",
       "\n",
       "### Group Members\n",
       "- [Student: Alice]\n",
       "- [Student: Brian]\n",
       "- [Student: Carol]"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Simulate Transaction Data\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Alice] Import libraries\n",
       "import pandas as pd  # Data manipulation\n",
       "import numpy as np   # Numerical operations\n",
       "import random        # Random sampling\n",
       "from mlxtend.frequent_patterns import apriori  # Apriori algorithm\n",
       "from mlxtend.frequent_patterns import association_rules  # For possible extension\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Alice] Set random seed for reproducibility\n",
       "random.seed(42)\n",
       "np.random.seed(42)\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Alice] Define pool of 30 unique supermarket items\n",
       "item_pool = [\n",
       "    'milk', 'bread', 'eggs', 'cheese', 'butter', 'apples', 'bananas', 'oranges', 'chicken', 'beef',\n",
       "    'fish', 'rice', 'pasta', 'tomatoes', 'potatoes', 'onions', 'lettuce', 'carrots', 'cereal', 'yogurt',\n",
       "    'juice', 'soda', 'coffee', 'tea', 'cookies', 'chips', 'waffles', 'candles', 'hard cheese', 'ice cream'\n",
       "]\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Alice] Simulate 3000 supermarket transactions\n",
       "n_transactions = 3000  # Number of transactions\n",
       "transactions = []      # List to store transactions\n",
       "for _ in range(n_transactions):\n",
       "    n_items = random.randint(2, 7)  # Each transaction has 2-7 items\n",
       "    transaction = random.sample(item_pool, n_items)\n",
       "    transactions.append(transaction)\n",
       "# Convert to DataFrame for export\n",
       "transactions_df = pd.DataFrame({'Transaction': [', '.join(t) for t in transactions]})\n",
       "transactions_df.to_csv('supermarket_transactions.csv', index=False)  # Save raw transactions\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Preprocessing: One-Hot Encoding\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Brian] One-hot encode the transactions\n",
       "onehot = pd.DataFrame(0, index=np.arange(n_transactions), columns=item_pool)  # Initialize\n",
       "for idx, items in enumerate(transactions):\n",
       "    for item in items:\n",
       "        onehot.at[idx, item] = 1  # Mark purchased items as 1\n",
       "onehot.to_csv('onehot_transactions.csv', index=False)  # Save one-hot encoded data\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Generate Frequent Itemsets (Apriori)\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Carol] Generate frequent itemsets using Apriori\n",
       "min_support = 0.05  # Minimum support threshold\n",
       "frequent_itemsets = apriori(onehot, min_support=min_support, use_colnames=True)\n",
       "frequent_itemsets = frequent_itemsets.sort_values('support', ascending=False)\n",
       "frequent_itemsets.to_csv('frequent_itemsets.csv', index=False)  # Save all frequent itemsets\n",
       "# Display top 10 frequent itemsets\n",
       "frequent_itemsets.head(10)\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Identify Closed Frequent Itemsets\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Brian] Identify closed frequent itemsets\n",
       "def is_closed(row, all_itemsets):\n",
       "    # For each superset, check if support is the same\n",
       "    for _, superset in all_itemsets.iterrows():\n",
       "        if row['itemsets'] < superset['itemsets'] and row['support'] == superset['support']:\n",
       "            return False\n",
       "    return True\n",
       "frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(frozenset)  # Ensure frozenset\n",
       "closed_mask = frequent_itemsets.apply(lambda row: is_closed(row, frequent_itemsets), axis=1)\n",
       "closed_itemsets = frequent_itemsets[closed_mask].copy()\n",
       "closed_itemsets.to_csv('closed_itemsets.csv', index=False)  # Save closed itemsets\n",
       "closed_itemsets.head(10)\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Identify Maximal Frequent Itemsets\n"
      ]
     },
     {
      "cell_type": "code",
      "metadata": {},
      "source": [
       "# [Student: Carol] Identify maximal frequent itemsets\n",
       "def is_maximal(row, all_itemsets):\n",
       "    # If any superset is also frequent, it's not maximal\n",
       "    for _, superset in all_itemsets.iterrows():\n",
       "        if row['itemsets'] < superset['itemsets']:\n",
       "            return False\n",
       "    return True\n",
       "maximal_mask = frequent_itemsets.apply(lambda row: is_maximal(row, frequent_itemsets), axis=1)\n",
       "maximal_itemsets = frequent_itemsets[maximal_mask].copy()\n",
       "maximal_itemsets.to_csv('maximal_itemsets.csv', index=False)  # Save maximal itemsets\n",
       "maximal_itemsets.head(10)\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Export Results to CSV\n",
       "All results are already exported in each step above.\n"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python",
      "version": "3.8"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
    